from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import requests
import json
import random
from typing import List, Optional, Dict, Any

app = FastAPI()

# è¨­å®š
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3.1" # RTX 5080 (16GB VRAM) æ¨å¥¨

# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
class PlayerData(BaseModel):
    name: str
    location: Dict[str, float]
    tags: Dict[str, List[str]]

class ChatData(BaseModel):
    sender: str
    message: str

class ReportData(BaseModel):
    players: List[PlayerData]
    chats: List[ChatData]
    events: List[Dict[str, Any]] = [] # New: Receive events like death, item use


class DiscordReportData(BaseModel):
    discord_user_id: int
    text: str
    t0: float
    t1: float

# --- Voxel Sensor Models ---
class PlayerInfo(BaseModel):
    name: str
    pos: dict
    rot: Optional[dict] = None
    dimension: str

class VoxelSnapshot(BaseModel):
    player: PlayerInfo
    origin: dict
    radius: int
    halfHeight: int
    width: int
    height: int
    grid: List[int]

@app.post("/v1/mc/state")
def receive_state(snapshot: VoxelSnapshot):
    """ãƒã‚¤ã‚¯ãƒ©ã‹ã‚‰ã®è¦–ç•Œãƒ‡ãƒ¼ã‚¿(Voxel)ã‚’å—ã‘å–ã‚‹"""
    # è»½å¿«ã«ãƒ­ã‚°ã ã‘å‡ºã™ (Debugç”¨)
    print(
        f"[VOXEL] {snapshot.player.name} "
        f"at ({snapshot.origin['x']},{snapshot.origin['y']},{snapshot.origin['z']}) "
        f"cells={len(snapshot.grid)}"
    )
    # ã“ã“ã« parkour_brain.update(snapshot) ã‚’æŒŸã‚€äºˆå®š
    return {"ok": True}

# ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã¨ã‚³ãƒãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¼
game_state = {
    "chat_history": [],
    "players": []
}
command_queue: List[Dict[str, Any]] = []
discord_queue: List[Dict[str, Any]] = []

def call_llm(prompt: str) -> Optional[str]:
    """Ollama (Local LLM) ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ã‚‹"""
    try:
        data = {
            "model": MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "format": "json"
        }
        response = requests.post(OLLAMA_URL, json=data)
        if response.status_code == 200:
            return json.loads(response.text)["response"]
        else:
            print(f"LLM Error: {response.status_code}")
            return None
    except Exception as e:
        print(f"LLM Connection Error: {e}")
        return None


@app.post("/v1/discord/report")
async def discord_report(data: DiscordReportData):
    """Discordã‹ã‚‰ã®éŸ³å£°èªè­˜çµæœã‚’å—ã‘å–ã‚‹"""
    global game_state
    
    print(f"[Discord Voice] {data.discord_user_id}: {data.text}")
    
    chat_entry = {
        "sender": f"Discord:{data.discord_user_id}",
        "message": data.text
    }
    game_state["chat_history"].append(chat_entry)
    
    # AIã«æ€è€ƒã•ã›ã‚‹
    await think_and_queue()
    
    return {"status": "ok"}

@app.post("/v1/report")
async def report(data: ReportData):
    """ãƒã‚¤ã‚¯ãƒ©ã‹ã‚‰ã®çŠ¶æ³å ±å‘Šã‚’å—ã‘å–ã‚‹"""
    global game_state, discord_queue
    
    # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®æ›´æ–°
    game_state["players"] = [p.dict() for p in data.players]
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´æ›´æ–° & èª­ã¿ä¸Šã’
    for chat in data.chats:
        print(f"Chat received: {chat.sender}: {chat.message}")
        game_state["chat_history"].append(chat.dict())
        
        # Discordã§èª­ã¿ä¸Šã’ (TTS)
        discord_queue.append({
            "type": "speak",
            "text": f"{chat.sender}ã€Œ{chat.message}ã€"
        })
        
        # ãƒãƒ£ãƒƒãƒˆã‚’å—ã‘å–ã£ãŸã‚‰æ€è€ƒã™ã‚‹
        await think_and_queue()

    # Process events through GameMaster (Mocking event extraction from report)
    # The actual implementation needs GameMaster integration here similar to previous plan
    # But for now, let's just show where Discord events would be handled if GM returns them.
    # In a real scenario, we'd extract events from data and pass to GM.
    # Since I don't have the full GM integration in this file yet (it was overwritten or missed in previous steps),
    # I will re-add the GM integration properly.
    
    from game_master import gm
    
    # Mock extracting events from data (needs client side support to send 'events' list)
    # For now, let's assume ReportData has an 'events' field in future, or we parse chat/actions.
    # To demonstrate the logic:
    
    minecraft_commands = []
    
    # Example: If GM returned commands, we separate them
    # events = data.events (NEED TO ADD TO MODEL)
    # for cmd in gm.process_event(event):
    #    if cmd.get("type") == "discord_event":
    #        discord_queue.append(cmd["event"])
    #    else:
    #        minecraft_commands.append(cmd)
            
    return {"status": "ok", "commands": minecraft_commands}

@app.post("/v1/discord/pull")
async def discord_pull():
    """Discord Botã‹ã‚‰ã®ãƒãƒ¼ãƒªãƒ³ã‚°ã«å¯¾ã—ã€æºœã¾ã£ã¦ã„ã‚‹ç™ºè¨€ã‚­ãƒ¥ãƒ¼ã‚’è¿”ã™"""
    global discord_queue
    
    if not discord_queue:
        return {"events": []}
    
    events_to_send = discord_queue.copy()
    discord_queue = []
    
    return {"events": events_to_send}

    return {"events": events_to_send}

class GameConfig(BaseModel):
    roles: Dict[str, int]

@app.post("/v1/game/start")
async def start_game():
    """Discordç­‰ã‹ã‚‰ã‚²ãƒ¼ãƒ é–‹å§‹ã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹"""
    from game_master import gm
    # Current config (can be stored in game_state)
    # For now, default or last config
    config = game_state.get("role_config", {"werewolf": 1})
    gm.start_game(config)
    
    # Send start message to Discord
    discord_queue.append({
        "type": "message",
        "channel_id": "DEFAULT",
        "content": "**ã‚²ãƒ¼ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼** ğŸ®"
    })
    discord_queue.append({
        "type": "speak",
        "text": "ã‚²ãƒ¼ãƒ ã‚’é–‹å§‹ã—ã¾ã™ã€‚å„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å½¹è·ã‚’é…å¸ƒã—ã¾ã—ãŸã€‚"
    })
    
    return {"status": "started", "config": config}

@app.post("/v1/game/config")
async def config_game(config: GameConfig):
    """å½¹è·æ§‹æˆã‚’è¨­å®šã™ã‚‹"""
    game_state["role_config"] = config.roles
    print(f"Game Config Updated: {config.roles}")
    return {"status": "updated", "config": config.roles}

async def think_and_queue():
    """AIã«æ€è€ƒã•ã›ã€çµæœã‚’ã‚³ãƒãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¼(ãƒã‚¤ã‚¯ãƒ©&Discord)ã«è¿½åŠ ã™ã‚‹"""
    print("AI Thinking...")
    
    prompt = f"""
    ã‚ãªãŸã¯Minecraftã®äººç‹¼ã‚²ãƒ¼ãƒ ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼(AIãƒœãƒƒãƒˆ)ã§ã™ã€‚
    ç¾åœ¨ã®çŠ¶æ³:
    - ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä¸€è¦§: {json.dumps(game_state['players'])}
    - ç›´è¿‘ã®ãƒãƒ£ãƒƒãƒˆ: {json.dumps(game_state['chat_history'][-5:])}
    
    ã‚¿ã‚°ã®è¦‹æ–¹:
    - pub: å…¬é–‹æƒ…å ± (å…¨å“¡ãŒè¦‹ãˆã‚‹çŠ¶æ…‹)
    - sec: ç§˜åŒ¿æƒ…å ± (å½¹è·ãªã©ã€ã‚ãªãŸã ã‘ãŒçŸ¥ã£ã¦ã„ã‚‹æƒ…å ±)
    
    ã‚ãªãŸã¯ã€Œæ‘äººã€ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
    æ€ªã—ã„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã„ã‚Œã°æ”»æ’ƒã—ã€ãƒãƒ£ãƒƒãƒˆã§ä¼šè©±ã—ã¦ãã ã•ã„ã€‚
    
    æ¬¡ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¡Œå‹•ã‚’æ±ºå®šã—ã¦ãã ã•ã„:
    {{
        "action": "move" | "attack" | "chat" | "idle",
        "target": "ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å (attack/moveã®å ´åˆ)",
        "message": "ãƒãƒ£ãƒƒãƒˆå†…å®¹ (chatã®å ´åˆ)",
        "reason": "è¡Œå‹•ã®ç†ç”±"
    }}
    å¿…ãšJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    
    llm_response = call_llm(prompt)
    if llm_response:
        try:
            action = json.loads(llm_response)
            print(f"AI Decided: {action}")
            
            # ãƒã‚¤ã‚¯ãƒ©ç”¨ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            command_queue.append(action)
            
            # ç™ºè¨€(chat)ãªã‚‰Discordç”¨ã‚­ãƒ¥ãƒ¼ã«ã‚‚è¿½åŠ ã—ã¦åŒæœŸã•ã›ã‚‹
            if action.get("action") == "chat" and action.get("message"):
                discord_queue.append({
                    "type": "speak",
                    "text": action["message"]
                })
                
        except:
            print("JSON Parse Error")

if __name__ == "__main__":
    print(f"Starting FastAPI Server on port 8080 (Model: {MODEL_NAME})...")
    uvicorn.run(app, host="0.0.0.0", port=8080)
